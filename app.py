import streamlit as st
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer, util
import torch
import os

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –°–¢–†–ê–ù–ò–¶–´ ---
st.set_page_config(
    page_title="–ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–π –ü–æ–∏—Å–∫",
    page_icon="üîç",
    layout="wide"
)

# --- –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ò (–ö–≠–®–ò–†–û–í–ê–ù–ò–ï) ---
@st.cache_resource
def load_model():
    return SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

try:
    with st.spinner('–ó–∞–≥—Ä—É–∑–∫–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏...'):
        model = load_model()
except Exception as e:
    st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
    st.stop()

# --- –§–£–ù–ö–¶–ò–Ø –ó–ê–ì–†–£–ó–ö–ò –î–ê–ù–ù–´–• ---
def load_data():
    csv_file = "company_policies.csv"
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å CSV —Ñ–∞–π–ª, –≥—Ä—É–∑–∏–º –µ–≥–æ
    if os.path.exists(csv_file):
        try:
            df = pd.read_csv(csv_file)
            # –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º DataFrame –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            return df.to_dict('records')
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è CSV: {e}")
            return []
    
    # –ò–Ω–∞—á–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    else:
        return [
            {"title": "–û—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –æ—Ç–ø—É—Å–∫–∞", "content": "–î–ª—è –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è –µ–∂–µ–≥–æ–¥–Ω–æ–≥–æ –æ–ø–ª–∞—á–∏–≤–∞–µ–º–æ–≥–æ –æ—Ç–ø—É—Å–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–æ–¥–∞—Ç—å –∑–∞—è–≤–ª–µ–Ω–∏–µ –≤ HR-–æ—Ç–¥–µ–ª –∑–∞ 2 –Ω–µ–¥–µ–ª–∏.", "category": "HR"},
            {"title": "–ù–∞—Å—Ç—Ä–æ–π–∫–∞ VPN", "content": "–î–ª—è —É–¥–∞–ª–µ–Ω–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ OpenVPN. –°–µ—Ä–≤–µ—Ä: vpn.company.com.", "category": "IT"},
            {"title": "–î—Ä–µ—Å—Å-–∫–æ–¥", "content": "–°—Ç–∏–ª—å Business Casual. –ü–æ –ø—è—Ç–Ω–∏—Ü–∞–º —Ä–∞–∑—Ä–µ—à–µ–Ω —Å–≤–æ–±–æ–¥–Ω—ã–π —Å—Ç–∏–ª—å.", "category": "HR"},
            {"title": "–ë–æ–ª—å–Ω–∏—á–Ω—ã–π", "content": "–°–æ–æ–±—â–∏—Ç–µ –Ω–æ–º–µ—Ä —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω–æ–≥–æ –±–æ–ª—å–Ω–∏—á–Ω–æ–≥–æ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—é.", "category": "HR"}
        ]

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è session_state –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
if 'documents' not in st.session_state:
    st.session_state.documents = load_data()

# --- –§–£–ù–ö–¶–ò–Ø –ü–û–ò–°–ö–ê ---
def search(query, docs, top_k=3):
    if not docs:
        return []
        
    corpus = [doc['content'] for doc in docs]
    
    query_embedding = model.encode(query, convert_to_tensor=True)
    corpus_embeddings = model.encode(corpus, convert_to_tensor=True)
    
    cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]
    top_results = torch.topk(cos_scores, k=min(top_k, len(corpus)))
    
    results = []
    for score, idx in zip(top_results[0], top_results[1]):
        doc_idx = int(idx)
        results.append({
            "score": float(score),
            "doc": docs[doc_idx]
        })
    return results

# --- –ò–ù–¢–ï–†–§–ï–ô–° (FRONTEND) ---

with st.sidebar:
    st.header("‚öôÔ∏è –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ")
    
    # –ö–Ω–æ–ø–∫–∞ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∏ –±–∞–∑—ã
    if st.button("üîÑ –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å –±–∞–∑—É –∏–∑ CSV"):
        st.session_state.documents = load_data()
        st.success(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(st.session_state.documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.")

    st.markdown("---")
    
    # –§–æ—Ä–º–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
    with st.expander("‚ûï –î–æ–±–∞–≤–∏—Ç—å –∑–∞–ø–∏—Å—å –≤—Ä—É—á–Ω—É—é"):
        new_title = st.text_input("–ó–∞–≥–æ–ª–æ–≤–æ–∫")
        new_cat = st.selectbox("–ö–∞—Ç–µ–≥–æ—Ä–∏—è", ["HR", "IT", "–§–∏–Ω–∞–Ω—Å—ã", "–ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ü–∏—è", "–î—Ä—É–≥–æ–µ"])
        new_content = st.text_area("–¢–µ–∫—Å—Ç")
        
        if st.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å"):
            if new_title and new_content:
                st.session_state.documents.append({
                    "title": new_title,
                    "content": new_content,
                    "category": new_cat
                })
                st.success("–î–æ–±–∞–≤–ª–µ–Ω–æ!")

    st.metric("–î–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å–µ", len(st.session_state.documents))

st.title("üß† –ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–π –ü–æ–∏—Å–∫")

# –ü—Ä–æ–≤–µ—Ä–∫–∞, –æ—Ç–∫—É–¥–∞ –¥–∞–Ω–Ω—ã–µ
if not os.path.exists("company_policies.csv"):
    st.info("üí° –°–æ–≤–µ—Ç: –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª `company_policies.csv` –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π GitHub, —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ–ª–Ω—É—é –±–∞–∑—É.")

query = st.text_input("–ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å:", placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: –ø–æ—Ç–µ—Ä—è–ª –ø—Ä–æ–ø—É—Å–∫ —á—Ç–æ –¥–µ–ª–∞—Ç—å?")

if query:
    with st.spinner('–ü–æ–∏—Å–∫...'):
        results = search(query, st.session_state.documents)
    
    if not results:
        st.warning("–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
    
    for hit in results:
        score = hit['score']
        doc = hit['doc']
        
        # –¶–≤–µ—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        color = "#e6ffe6" if score > 0.6 else "#fffbe6" if score > 0.4 else "#fff0f0"
        
        with st.container():
            st.markdown(f"""
            <div style="background-color: {color}; padding: 15px; border-radius: 10px; margin-bottom: 10px; border: 1px solid #ddd;">
                <div style="display:flex; justify-content:space-between;">
                    <h4 style="margin:0;">{doc.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}</h4>
                    <span style="background:#ddd; padding:2px 8px; border-radius:10px; font-size:0.8em;">{doc.get('category', '–û–±—â–µ–µ')}</span>
                </div>
                <p style="margin-top:10px;">{doc.get('content', '')}</p>
                <div style="font-size:0.8em; color:gray; margin-top:5px;">–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {score:.1%}</div>
            </div>
            """, unsafe_allow_html=True)

with st.expander("üìÇ –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ"):
    st.dataframe(pd.DataFrame(st.session_state.documents))